---
layout: post
title: HARVARD
---

[experimental endpoint](https://github.com/harvardartmuseums/api-docs/blob/master/experimental.md)

>The data is a result of machine processing data and images through external services including Google Vision, Microsoft Cognitive Services, Imagga, and Clarifai. We are using the services to perform face detection, text detection, color analysis, and automatic feature detection/tagging of images. We have not created training sets for these services. We are feeding in our images and data as-is to see what comes out.

We went with the plain old object endpoint user generated keyword. I like to do this with mundane words like dog and pink. my two fave images are

![white dog biting brown dog](http://nrs.harvard.edu/urn-3:HUAM:INV156245_dynmc?width=3000&height=3000)

![bulldog in pink bathroom](http://nrs.harvard.edu/urn-3:HUAM:INV156243_dynmc?width=3000&height=3000)

Images on this website are available to download for personal, noncommercial use, including for publication on personal websites and blogs. As a courtesy, please include the credit line “Harvard Art Museums” as well as the original image URL.
http://www.harvardartmuseums.org/collections/object/158697

http://www.harvardartmuseums.org/collections/object/158716

turns out they are both by ann wulff from her book of photographs "caged tigers" published in 1981. amazing!

91% of the objects in the collection has at least one image, however, whether the image is available through the api is a matter of rights restrictions, I'm guessing mostly modern and contemporary works under copyright.

http://api.harvardartmuseums.org/object?apikey=48d94c00-f18a-11e6-89ba-839d228fa55c

 The hue has been slowly shifting along a 365-day color spectrum: by May the hue had transitioned to green, which then turned to yellow in July, bringing us to the orange of September. By year’s end we’ll cool back down to blue. Each day in the year has its unique hue, marking its specific moment in time.

provenance and total page views

emotion likely hood (google vision), position of features at x, y axis. facemapping, likelyhood that they are wearing Hats

clearly a spaniel dressed as Donald Duck.
![spaniel dressed as Donald Duck](http://ids.lib.harvard.edu/ids/view/20415768)
randomly found this negative of a dog, a spaniel wearing perhaps a donald duck outfit.
endpoint for color which is hex and names of all colors used to describe works in the collection. idk why you would use this.
``` json
{
  id: 34838474,
  lastupdate: "2017-04-19T04:12:10-0400",
  hex: "#dcdcdc",
  name: "gainsboro",
  colorid: 34838474
}
```
